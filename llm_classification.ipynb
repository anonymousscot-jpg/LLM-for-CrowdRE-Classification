{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Open source llms-2.csv') # replace with your dataset\n",
    "display(df.head())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in 'Parameter in B':\", df['Parameter in B'].isnull().sum())\n",
    "print(\"Missing values in 'Typical Download Size(int_4) in GB':\", df['Typical Download Size(int_4) in GB'].isnull().sum())\n",
    "\n",
    "print(\"\\nData type of 'Parameter in B':\", df['Parameter in B'].dtype)\n",
    "print(\"Data type of 'Typical Download Size(int_4) in GB':\", df['Typical Download Size(int_4) in GB'].dtype)\n",
    "\n",
    "# Drop unnamed columns with all null values\n",
    "unnamed_cols = [col for col in df.columns if 'Unnamed:' in col and df[col].isnull().all()]\n",
    "df_cleaned = df.drop(columns=unnamed_cols)\n",
    "\n",
    "display(df_cleaned.head())\n",
    "display(df_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477cd136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_clustering = df_cleaned[['Parameter in B', 'Typical Download Size(int_4) in GB']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_clustering)\n",
    "\n",
    "display(scaled_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "kmeans_model.fit(scaled_data)\n",
    "cluster_labels = kmeans_model.labels_\n",
    "\n",
    "display(cluster_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb17dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['cluster_label'] = cluster_labels\n",
    "\n",
    "cluster_means = df_cleaned.groupby('cluster_label')[['Parameter in B', 'Typical Download Size(int_4) in GB']].mean()\n",
    "display(cluster_means)\n",
    "\n",
    "# Determine the mapping based on the cluster means\n",
    "# Assuming lower means correspond to smaller categories and higher means to larger categories\n",
    "# We sort the clusters based on the sum of their mean 'Parameter in B' and 'Typical Download Size(int_4) in GB'\n",
    "cluster_means['sum_means'] = cluster_means['Parameter in B'] + cluster_means['Typical Download Size(int_4) in GB']\n",
    "cluster_means_sorted = cluster_means.sort_values('sum_means')\n",
    "\n",
    "mapping = {\n",
    "    cluster_means_sorted.index[0]: 'tiny',\n",
    "    cluster_means_sorted.index[1]: 'small',\n",
    "    cluster_means_sorted.index[2]: 'medium',\n",
    "    cluster_means_sorted.index[3]: 'large',\n",
    "    cluster_means_sorted.index[4]: 'Ultra',\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df_cleaned['category'] = df_cleaned['cluster_label'].map(mapping)\n",
    "\n",
    "display(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251dc2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "categories = df_cleaned['category'].unique()\n",
    "colors = ['blue', 'red', 'green', 'purple','pink'] # Assign a color for each category\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    subset = df_cleaned[df_cleaned['category'] == category]\n",
    "    plt.scatter(subset['Parameter in B'], subset['Typical Download Size(int_4) in GB'],\n",
    "                color=colors[i], label=category, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Parameter in B')\n",
    "plt.ylabel('Typical Download Size (GB)')\n",
    "plt.title('LLM Clustering based on Parameter Size and Download Size')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ec8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_category = df_cleaned.groupby('category')['Model Name'].apply(list)\n",
    "\n",
    "for category, models in grouped_by_category.items():\n",
    "    print(f\"Category: {category}\")\n",
    "    print(\"Models:\", models)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the optimum number of clusters using the Elbow Method\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sse = []\n",
    "k_range = range(3, 10)  # Check clusters from 4 to 8\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(scaled_data)\n",
    "    sse.append(kmeans.inertia_) # Inertia is the sum of squared distances of samples to their closest cluster center\n",
    "\n",
    "# Plotting the Elbow Method graph\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_range, sse, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Sum of squared errors (SSE)')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Based on the plot, choose the optimal k (where the elbow occurs)\n",
    "# Let's assume the optimal k is determined from the plot (replace optimal_k with the value you find)\n",
    "# For demonstration, let's say the optimal k is 5 (you should determine this from the plot)\n",
    "optimal_k = 4 # Replace with the actual optimal k from the plot\n",
    "\n",
    "# Apply K-Means with the optimal number of clusters\n",
    "kmeans_optimal = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "kmeans_optimal.fit(scaled_data)\n",
    "cluster_labels_optimal = kmeans_optimal.labels_\n",
    "\n",
    "# Add the optimal cluster labels to the dataframe\n",
    "df_cleaned['optimal_cluster_label'] = cluster_labels_optimal\n",
    "\n",
    "# You can then proceed with mapping these optimal cluster labels to categories\n",
    "# similar to how you did before, or analyze the clusters directly.\n",
    "# The mapping logic might need to be adjusted based on the optimal number of clusters.\n",
    "\n",
    "# Display the head of the dataframe with optimal cluster labels\n",
    "display(df_cleaned.head())\n",
    "\n",
    "# To see the distribution of models in the optimal clusters:\n",
    "print(\"\\nModels in each optimal cluster:\")\n",
    "grouped_by_optimal_cluster = df_cleaned.groupby('optimal_cluster_label')['Model Name'].apply(list)\n",
    "for cluster, models in grouped_by_optimal_cluster.items():\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    print(\"Models:\", models)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1291a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'scaled_data' is already defined and contains your scaled data\n",
    "# Assuming 'df_cleaned' is already defined\n",
    "\n",
    "silhouette_scores = []\n",
    "k_range = range(3, 10)  # Check clusters from 2 to 9\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(scaled_data)\n",
    "    score = silhouette_score(scaled_data, kmeans.labels_)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Plotting the Silhouette scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_range, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Method for Optimal k')\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the k with the highest silhouette score\n",
    "optimal_k_silhouette = k_range[silhouette_scores.index(max(silhouette_scores))]\n",
    "print(f\"Optimal number of clusters based on Silhouette Method: {optimal_k_silhouette}\")\n",
    "\n",
    "# Apply K-Means with the optimal number of clusters found by Silhouette Method\n",
    "kmeans_silhouette = KMeans(n_clusters=optimal_k_silhouette, random_state=42, n_init=10)\n",
    "kmeans_silhouette.fit(scaled_data)\n",
    "cluster_labels_silhouette = kmeans_silhouette.labels_\n",
    "\n",
    "# Add the optimal cluster labels to the dataframe\n",
    "df_cleaned['silhouette_cluster_label'] = cluster_labels_silhouette\n",
    "\n",
    "# Display the head of the dataframe with optimal cluster labels from Silhouette method\n",
    "display(df_cleaned.head())\n",
    "\n",
    "# To see the distribution of models in the optimal clusters from Silhouette method:\n",
    "print(\"\\nModels in each optimal cluster (Silhouette Method):\")\n",
    "grouped_by_silhouette_cluster = df_cleaned.groupby('silhouette_cluster_label')['Model Name'].apply(list)\n",
    "for cluster, models in grouped_by_silhouette_cluster.items():\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    print(\"Models:\", models)\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
